{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed: 999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fca9b906170>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torchvision.transforms import Compose, CenterCrop, Normalize, ToTensor\n",
    "from glob import glob\n",
    "\n",
    "import nibabel as nib \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import binary as bin_eval\n",
    "\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "manualSeed = 999\n",
    "\n",
    "print(\"Random Seed:\", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "test_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLabel(object):\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "    \n",
    "        tensor[tensor > 0] = 1\n",
    "        tensor[tensor < 0] = 0\n",
    "        \n",
    "        return tensor\n",
    "\n",
    "class ReImage(object):\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "    \n",
    "        t_max = tensor.max()\n",
    "        tensor = tensor/t_max\n",
    "        \n",
    "        return tensor     \n",
    "    \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root):\n",
    "\n",
    "        self.root = root\n",
    "        \n",
    "        if not os.path.exists(self.root):\n",
    "            raise Exception(\"[!] {} not exists.\".format(root))\n",
    "        \n",
    "        self.img_transform = Compose([\n",
    "            \n",
    "            ReImage(),\n",
    "        ])\n",
    "        \n",
    "        self.label_transform = Compose([\n",
    "            \n",
    "            ReLabel(),\n",
    "        ])\n",
    "        \n",
    "        #sort file names\n",
    "        self.input_paths = sorted(glob(os.path.join(self.root, '{}/*.npy'.format(\"3D_data_4/train_data\"))))\n",
    "        self.label_paths = sorted(glob(os.path.join(self.root, '{}/*.npy'.format(\"3D_data_4/train_lab\"))))\n",
    "        self.name = os.path.basename(root)\n",
    "        \n",
    "        if len(self.input_paths) == 0 or len(self.label_paths) == 0:\n",
    "            raise Exception(\"No images/labels are found in {}\".format(self.root))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "               \n",
    "        image = np.load(self.input_paths[index])\n",
    "        label = np.load(self.label_paths[index])\n",
    "\n",
    "        image = image[np.newaxis,:,:,:]\n",
    "        label = label[np.newaxis,:,:,:]\n",
    "        \n",
    "        image = image.astype(np.float32)\n",
    "        label = label.astype(np.float32)\n",
    "        \n",
    "        image = self.img_transform(image)\n",
    "        label = self.label_transform(label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_paths)\n",
    "\n",
    "    \n",
    "class Dataset_test(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root):\n",
    "\n",
    "        self.root = root\n",
    "        \n",
    "        if not os.path.exists(self.root):\n",
    "            raise Exception(\"[!] {} not exists.\".format(root))\n",
    "        \n",
    "        self.img_transform = Compose([\n",
    "            ReImage(),    \n",
    "        ])\n",
    "        \n",
    "        self.label_transform = Compose([\n",
    "            ReLabel(),\n",
    "        ])\n",
    "        \n",
    "        #sort file names\n",
    "        self.input_paths = sorted(glob(os.path.join(self.root, '{}/*.npy'.format(\"3D_data_4/test_data\"))))\n",
    "        self.label_paths = sorted(glob(os.path.join(self.root, '{}/*.npy'.format(\"3D_data_4/test_lab\"))))\n",
    "        self.name = os.path.basename(root)\n",
    "        \n",
    "        if len(self.input_paths) == 0 or len(self.label_paths) == 0:\n",
    "            raise Exception(\"No images/labels are found in {}\".format(self.root))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "               \n",
    "        image = np.load(self.input_paths[index])\n",
    "        label = np.load(self.label_paths[index])\n",
    "\n",
    "        image = image[np.newaxis,:,:,:]\n",
    "        label = label[np.newaxis,:,:,:]\n",
    "        \n",
    "        image = image.astype(np.float32)\n",
    "        label = label.astype(np.float32)        \n",
    "        \n",
    "        image = self.img_transform(image)\n",
    "        label = self.label_transform(label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def loader(dataset, batch_size, num_workers=6, shuffle = False, drop_last=False):\n",
    "\n",
    "    input_images = dataset\n",
    "    input_loader = torch.utils.data.DataLoader(dataset=input_images, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, drop_last=drop_last)\n",
    "\n",
    "    return input_loader\n",
    "\n",
    "train_loader = loader(Dataset('../'), batch_size= batch_size, shuffle = True, drop_last=True)\n",
    "test_loader = loader(Dataset_test('../'), batch_size= test_size, shuffle = False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "print(train_loader.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#High-level Feature Enhancement Module\n",
    "\n",
    "class Vox_Att(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_ch):\n",
    "        super(Vox_Att, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, int(in_ch/2), kernel_size=3, padding=1),\n",
    "            nn.GroupNorm(8, int(in_ch/2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(int(in_ch/2), int(in_ch/2), kernel_size=3, padding=5, dilation=5),\n",
    "            nn.GroupNorm(8, int(in_ch/2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv3d(int(in_ch/2), in_ch, kernel_size=3, padding=1),\n",
    "            nn.GroupNorm(8, in_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.output = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, in_x):\n",
    "        \n",
    "        x = self.conv1(in_x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        \n",
    "        return in_x * x + in_x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv3d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "class double_conv_HL(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv_HL, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv3d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        return x    \n",
    "    \n",
    "class single_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(single_conv, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        return x    \n",
    "    \n",
    "#Low-level Feature Enhancement Module\n",
    "\n",
    "class High_map(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(High_map, self).__init__()\n",
    "        \n",
    "        self.Sconv1 = single_conv(in_ch, out_ch)\n",
    "        self.pool1 = nn.MaxPool3d((1,2,2))\n",
    "        \n",
    "        self.Sconv2 = single_conv(out_ch, out_ch)       \n",
    "        self.pool2 = nn.MaxPool3d((1,2,2))\n",
    "        \n",
    "        self.Sconv3 = single_conv(out_ch, out_ch*2)           \n",
    "        \n",
    "        self.Tconv1 = nn.ConvTranspose3d(out_ch*2, out_ch, kernel_size=(1,2,2), stride=(1,2,2), padding=0)\n",
    "        self.Sconv4 = single_conv(out_ch*2, out_ch)\n",
    "        \n",
    "        self.Tconv2 = nn.ConvTranspose3d(out_ch, out_ch, kernel_size=(1,2,2), stride=(1,2,2), padding=0)\n",
    "        self.Sconv5 = single_conv(out_ch*2, out_ch)        \n",
    "        \n",
    "        self.conv6 = nn.Conv3d(out_ch, 1, kernel_size=1, stride=1, padding=0)\n",
    "        self.output = nn.Sigmoid()  \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        c1 = self.Sconv1(x)\n",
    "        p1 = self.pool1(c1)\n",
    "        \n",
    "        c2 = self.Sconv2(p1)\n",
    "        p2 = self.pool2(c2)\n",
    "        \n",
    "        c3 = self.Sconv3(p2)\n",
    "        \n",
    "        t1 = self.Tconv1(c3)\n",
    "        x1 = torch.cat([c2, t1], dim=1)\n",
    "        c4 = self.Sconv4(x1)\n",
    "        \n",
    "        t2 = self.Tconv2(c4)\n",
    "        x2 = torch.cat([c1, t2], dim=1)\n",
    "        c5 = self.Sconv5(x2) \n",
    "        \n",
    "        c6 = self.conv6(c5) \n",
    "        \n",
    "        map_x = self.output(c6)\n",
    "        \n",
    "        return map_x\n",
    "\n",
    "      \n",
    "class High_to_Low(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(High_to_Low, self).__init__()\n",
    "        \n",
    "        self.Dconv1 = double_conv_HL(in_ch, out_ch)\n",
    "        \n",
    "        self.High_Map = High_map(in_ch, out_ch)\n",
    "        \n",
    "        self.Sconv1 = single_conv(out_ch, out_ch)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        D_x = self.Dconv1(x)\n",
    "        \n",
    "        H_x = self.High_Map(x)\n",
    "        \n",
    "        Mix_x = torch.add(D_x*H_x, D_x)\n",
    "        \n",
    "        out_x = self.Sconv1(Mix_x)\n",
    "        \n",
    "        return out_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 1\n",
    "numf = 16\n",
    "\n",
    "class G_unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(G_unet, self).__init__()\n",
    "        \n",
    "        self.Dconv1 = High_to_Low(input, numf)       \n",
    "        self.pool1 = nn.MaxPool3d((1,2,2))\n",
    "        \n",
    "        self.Dconv2 = High_to_Low(numf, numf*2)           \n",
    "        self.pool2 = nn.MaxPool3d((1,2,2))        \n",
    "        \n",
    "        self.Dconv3 = High_to_Low(numf*2, numf*3)          \n",
    "        self.pool3 = nn.MaxPool3d(2)     \n",
    "        \n",
    "        self.Dconv4 = High_to_Low(numf*3, numf*4)              \n",
    "        self.pool4 = nn.MaxPool3d(2)\n",
    "        \n",
    "        self.Dconv5 = double_conv(numf*4, numf*8) \n",
    "        \n",
    "        self.Tconv1 = nn.ConvTranspose3d(numf*8, numf*4, kernel_size=2, stride=2, padding=0)\n",
    "        self.AVgate1 = Vox_Att(numf*8)\n",
    "        self.Dconv6 = double_conv(numf*8, numf*4) \n",
    "        \n",
    "        self.Tconv2 = nn.ConvTranspose3d(numf*4, numf*3, kernel_size=2, stride=2, padding=0)\n",
    "        self.AVgate2 = Vox_Att(numf*6)\n",
    "        self.Dconv7 = double_conv(numf*6, numf*3)        \n",
    "        \n",
    "        self.Tconv3 = nn.ConvTranspose3d(numf*3, numf*2, kernel_size=(1,2,2), stride=(1,2,2), padding=0)\n",
    "        self.AVgate3 = Vox_Att(numf*4)\n",
    "        self.Dconv8 = double_conv(numf*4, numf*2)          \n",
    "        \n",
    "        self.Tconv4 = nn.ConvTranspose3d(numf*2, numf, kernel_size=(1,2,2), stride=(1,2,2), padding=0)\n",
    "        self.AVgate4 = Vox_Att(numf*2)\n",
    "        self.Dconv9 = double_conv(numf*2, numf)   \n",
    "        \n",
    "        self.conv19 = nn.Conv3d(numf, 1, kernel_size=1, stride=1, padding=0)\n",
    "        self.output = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        c1 = self.Dconv1(input)\n",
    "        p1 = self.pool1(c1)\n",
    "            \n",
    "        c2 = self.Dconv2(p1)\n",
    "        p2 = self.pool2(c2)  \n",
    "        \n",
    "        c3 = self.Dconv3(p2)\n",
    "        p3 = self.pool3(c3)  \n",
    "        \n",
    "        c4 = self.Dconv4(p3)\n",
    "        p4 = self.pool4(c4)\n",
    "        \n",
    "        c5 = self.Dconv5(p4)\n",
    "        \n",
    "        t1 = self.Tconv1(c5)\n",
    "        x1 = torch.cat([c4, t1], dim=1)\n",
    "        x1 = self.AVgate1(x1)\n",
    "        c6 = self.Dconv6(x1)\n",
    "        \n",
    "        t2 = self.Tconv2(c6)\n",
    "        x2 = torch.cat([c3, t2], dim=1)\n",
    "        x2 = self.AVgate2(x2)\n",
    "        c7 = self.Dconv7(x2)         \n",
    "        \n",
    "        t3 = self.Tconv3(c7)\n",
    "        x3 = torch.cat([c2, t3], dim=1)\n",
    "        x3 = self.AVgate3(x3)\n",
    "        c8 = self.Dconv8(x3)   \n",
    "        \n",
    "        t4 = self.Tconv4(c8)\n",
    "        x4 = torch.cat([c1, t4], dim=1)\n",
    "        x4 = self.AVgate4(x4)\n",
    "        c9 = self.Dconv9(x4)\n",
    "        \n",
    "        c19 = self.conv19(c9)\n",
    "        \n",
    "        output = self.output(c19)\n",
    "            \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_unet(\n",
      "  (Dconv1): High_to_Low(\n",
      "    (Dconv1): double_conv_HL(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "        (5): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (High_Map): High_map(\n",
      "      (Sconv1): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (Sconv2): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (pool2): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (Sconv3): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (Tconv1): ConvTranspose3d(32, 16, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
      "      (Sconv4): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (Tconv2): ConvTranspose3d(16, 16, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
      "      (Sconv5): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (conv6): Conv3d(16, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      (output): Sigmoid()\n",
      "    )\n",
      "    (Sconv1): single_conv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (Dconv2): High_to_Low(\n",
      "    (Dconv1): double_conv_HL(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        (5): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (High_Map): High_map(\n",
      "      (Sconv1): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (Sconv2): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (pool2): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (Sconv3): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (Tconv1): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
      "      (Sconv4): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (Tconv2): ConvTranspose3d(32, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
      "      (Sconv5): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (conv6): Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      (output): Sigmoid()\n",
      "    )\n",
      "    (Sconv1): single_conv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool2): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (Dconv3): High_to_Low(\n",
      "    (Dconv1): double_conv_HL(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(32, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
      "        (5): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (High_Map): High_map(\n",
      "      (Sconv1): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(32, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (Sconv2): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (pool2): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (Sconv3): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (Tconv1): ConvTranspose3d(96, 48, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
      "      (Sconv4): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (Tconv2): ConvTranspose3d(48, 48, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
      "      (Sconv5): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (conv6): Conv3d(48, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      (output): Sigmoid()\n",
      "    )\n",
      "    (Sconv1): single_conv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Dconv4): High_to_Low(\n",
      "    (Dconv1): double_conv_HL(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(48, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        (5): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (High_Map): High_map(\n",
      "      (Sconv1): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(48, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (Sconv2): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (pool2): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (Sconv3): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (Tconv1): ConvTranspose3d(128, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
      "      (Sconv4): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (Tconv2): ConvTranspose3d(64, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
      "      (Sconv5): single_conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (conv6): Conv3d(64, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      (output): Sigmoid()\n",
      "    )\n",
      "    (Sconv1): single_conv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool4): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Dconv5): double_conv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (4): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "      (5): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (Tconv1): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "  (AVgate1): Vox_Att(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(5, 5, 5), dilation=(5, 5, 5))\n",
      "      (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (output): Sigmoid()\n",
      "  )\n",
      "  (Dconv6): double_conv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (4): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "      (5): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (Tconv2): ConvTranspose3d(64, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "  (AVgate2): Vox_Att(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(5, 5, 5), dilation=(5, 5, 5))\n",
      "      (1): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (output): Sigmoid()\n",
      "  )\n",
      "  (Dconv7): double_conv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (4): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
      "      (5): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (Tconv3): ConvTranspose3d(48, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
      "  (AVgate3): Vox_Att(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(5, 5, 5), dilation=(5, 5, 5))\n",
      "      (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (output): Sigmoid()\n",
      "  )\n",
      "  (Dconv8): double_conv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "      (5): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (Tconv4): ConvTranspose3d(32, 16, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
      "  (AVgate4): Vox_Att(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(5, 5, 5), dilation=(5, 5, 5))\n",
      "      (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (output): Sigmoid()\n",
      "  )\n",
      "  (Dconv9): double_conv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (4): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "      (5): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (conv19): Conv3d(16, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (output): Sigmoid()\n",
      ")\n",
      "# CFENet parameters: 4665109\n"
     ]
    }
   ],
   "source": [
    "CFENet = G_unet().to(device)\n",
    "\n",
    "print(CFENet)\n",
    "\n",
    "print('# CFENet parameters:', sum(param.numel() for param in CFENet.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1, eps=1e-7):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, preds, labels):\n",
    "    \n",
    "        return 1 - (2 * torch.sum(preds * labels) + self.smooth) / (torch.sum(preds) + torch.sum(labels) + self.smooth)\n",
    "\n",
    "\n",
    "class jaccard_Loss(nn.Module):\n",
    "    def __init__(self, smooth=1, eps=1e-7):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, preds, labels):\n",
    "        \n",
    "        intersection = torch.sum(preds * labels)\n",
    "        return 1 - (intersection + self.smooth) / (torch.sum(preds) + torch.sum(labels) - intersection + self.smooth)    \n",
    "    \n",
    "\n",
    "def jaccard_coef(preds, labels):\n",
    "    \n",
    "    smooth=1\n",
    "    eps=1e-7\n",
    "    \n",
    "    intersection = torch.sum(preds * labels)\n",
    "    return (intersection + smooth) / (torch.sum(preds) + torch.sum(labels) - intersection + smooth)\n",
    "          \n",
    "def dice_coef(preds, labels):\n",
    "    \n",
    "    smooth=1\n",
    "    eps=1e-7\n",
    "    \n",
    "    return (2 * torch.sum(preds * labels) + smooth) / (torch.sum(preds) + torch.sum(labels) + smooth)\n",
    "\n",
    "\n",
    "def com_evaluation(preds, labels):\n",
    "    \n",
    "    smooth=1\n",
    "    eps=1e-7\n",
    "    \n",
    "    intersection = torch.sum(labels * preds)\n",
    "    num_pred = torch.sum(preds)\n",
    "    num_lab = torch.sum(labels)\n",
    "    \n",
    "    jaccard = (intersection + smooth) / (num_pred + num_lab - intersection + smooth)\n",
    "    dice = (2 * intersection + smooth) / (num_pred + num_lab + smooth)\n",
    "\n",
    "    pre_list = preds.cpu().numpy()\n",
    "    lab_list = labels.cpu().numpy()\n",
    "    assd = bin_eval.assd(pre_list, lab_list)\n",
    "    \n",
    "    return jaccard, dice, assd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Criterion = DiceLoss()\n",
    "\n",
    "C_optimizer = torch.optim.Adam(CFENet.parameters(), lr=0.0001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(C_optimizer, step_size=20, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "\n",
    "for epoch in range(300):\n",
    "    \n",
    "    run_dice_loss = 0.0\n",
    "    running_jaccard = 0.0\n",
    "\n",
    "    test_dice = 0.0\n",
    "    test_jaccard = 0.0\n",
    "    test_assd = 0.0\n",
    "\n",
    "    test_i = 0\n",
    "    train_i = 0\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    for param_group in C_optimizer.param_groups:\n",
    "        if epoch % 20 == 0:\n",
    "            print(param_group['lr'])\n",
    "    \n",
    "    \n",
    "    for i_1, train_data in enumerate(train_loader):\n",
    "        \n",
    "        inputs, labels = train_data\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "             \n",
    "        pre_labs = CFENet(inputs)\n",
    "        dice_loss = Criterion(labels, pre_labs)\n",
    "        \n",
    "        jaccard = jaccard_coef(pre_labs, labels)\n",
    "\n",
    "        C_optimizer.zero_grad()\n",
    "        dice_loss.backward()\n",
    "        C_optimizer.step()\n",
    "\n",
    "        running_jaccard += jaccard\n",
    "        run_dice_loss += dice_loss.item()\n",
    "        \n",
    "        train_i += 1\n",
    "\n",
    "        \n",
    "    for i_2, test_data in enumerate(test_loader): \n",
    "  \n",
    "        with torch.no_grad():   \n",
    "            \n",
    "            inputs, labels = test_data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            pre_labs = CFENet(inputs)\n",
    "            \n",
    "            pre_labs[pre_labs < 0.5] = 0\n",
    "            pre_labs[pre_labs >= 0.5] = 1\n",
    "            \n",
    "            jaccard, dice, assd = com_evaluation(pre_labs, labels)\n",
    "            \n",
    "            test_jaccard += jaccard\n",
    "            test_dice += dice\n",
    "            test_assd += assd\n",
    "            \n",
    "            test_i += 1\n",
    "                                        \n",
    "    list.append(test_jaccard)\n",
    "    #print(test_i)\n",
    "\n",
    "    if  max(list) == test_jaccard:\n",
    "\n",
    "        torch.save(CFENet, \"HL-LH_4.pkl\")\n",
    "        print(\"-------Save %d epoch model---------\"% epoch)\n",
    "\n",
    "    print('e: %d, d_loss: %.5f, tr_jacc: %.5f,' % \n",
    "          (epoch, run_dice_loss/train_i, running_jaccard/train_i))\n",
    "    print('test_dice: %.5f, test_jacc: %.5f, test_acc: %.5f,' % \n",
    "          (test_dice/test_i, test_jaccard/test_i, test_assd/test_i))\n",
    "    print('-----------------------------------------------')\n",
    "            \n",
    "    run_dice_loss = 0.0\n",
    "    running_jaccard = 0.0\n",
    "\n",
    "    test_dice = 0.0\n",
    "    test_jaccard = 0.0\n",
    "    test_assd = 0.0\n",
    "\n",
    "    test_i = 0\n",
    "    train_i = 0\n",
    "                         \n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_11",
   "language": "python",
   "name": "pytorch_11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
